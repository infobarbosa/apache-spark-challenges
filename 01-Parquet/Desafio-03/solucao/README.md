# Apache Spark Challenges
Author: Prof. Barbosa<br>
Contact: infobarbosa@gmail.com<br>
Github: [infobarbosa](https://github.com/infobarbosa)

# Arquivos Parquet

```
source="./assets/beneficiarios.parquet"
output="./output/beneficiarios-dedup.parquet"
```
1. Leia o arquivo parquet;
```
df1 = spark.read.parquet(source)
```
2. Crie um dataframe;
```
```
3. Elimine duplicidades;
```
```
4. Escreva o resultado no data lake.
```
```


